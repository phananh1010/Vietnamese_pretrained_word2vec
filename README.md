# Vietnamese_pretrained_word2vec
This is trained Word2Vec model for Vietnamese language. The model is trained on news websites crawled from vnexpress.net, dantri.com.vn, and tuoitre.vn. Currently the crawled data has more than 60,000 articles, with total of 509806 sentences, or 12 millions words. The model can be directly used to derived the vector representation of words. 

A. Some usecases of this model

B. How to use
 
